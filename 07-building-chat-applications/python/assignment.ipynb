{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31016cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "model = \"deepseek-v3\"\n",
    "# model = \"deepseek-r1\"\n",
    "\n",
    "md_display = lambda text: display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "130aeaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The use of the Oxford comma (also known as the serial comma) is a matter of style and preference, and it is not always required. Whether to use it depends on the style guide you are following or the conventions of the context in which you are writing. Here’s a breakdown:\n",
       "\n",
       "### **When to Use the Oxford Comma:**\n",
       "1. **Clarity:** The Oxford comma can prevent ambiguity in sentences. For example:\n",
       "   - *Without Oxford comma:* \"I invited my parents, Beyoncé and Barack Obama.\" (This could imply that your parents are Beyoncé and Barack Obama.)\n",
       "   - *With Oxford comma:* \"I invited my parents, Beyoncé, and Barack Obama.\" (This makes it clear that there are three separate entities.)\n",
       "\n",
       "2. **Style Guides:** Some style guides, such as **The Chicago Manual of Style**, **APA**, and **MLA**, recommend using the Oxford comma for consistency and clarity.\n",
       "\n",
       "3. **Formal Writing:** In academic, technical, or professional writing, the Oxford comma is often preferred to avoid misunderstandings.\n",
       "\n",
       "### **When It’s Optional or Not Used:**\n",
       "1. **Journalism and Media:** Some style guides, like **The Associated Press (AP) Stylebook**, generally omit the Oxford comma unless it’s necessary for clarity.\n",
       "\n",
       "2. **Informal Writing:** In casual or creative writing, the Oxford comma is often left out if the meaning is clear without it.\n",
       "\n",
       "3. **Regional Preferences:** In British English, the Oxford comma is less commonly used than in American English, though it’s not strictly forbidden.\n",
       "\n",
       "### **Key Takeaway:**\n",
       "- **Use the Oxford comma** if it improves clarity or if your style guide requires it.\n",
       "- **Omit it** if your style guide or context prefers it that way, and the sentence remains unambiguous.\n",
       "- **Be consistent** in your usage throughout a document or piece of writing.\n",
       "\n",
       "Ultimately, the decision depends on your audience, purpose, and the conventions you’re following."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "md_display(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0d38ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The use of the Oxford comma (also known as the serial comma) is a matter of style and preference, and whether it should always be used depends on the context and the style guide you are following. Here’s a breakdown:\n",
       "\n",
       "### **When to Use the Oxford Comma**\n",
       "1. **Clarity**: The Oxford comma can prevent ambiguity in sentences. For example:\n",
       "   - Without Oxford comma: \"I love my parents, Lady Gaga and Humpty Dumpty.\" (This could imply that your parents are Lady Gaga and Humpty Dumpty.)\n",
       "   - With Oxford comma: \"I love my parents, Lady Gaga, and Humpty Dumpty.\" (This clearly lists three separate entities.)\n",
       "\n",
       "2. **Style Guides**: Some style guides, such as *The Chicago Manual of Style* and *The Oxford Style Manual*, recommend using the Oxford comma consistently.\n",
       "\n",
       "3. **Formal Writing**: In academic, legal, or technical writing, the Oxford comma is often preferred to ensure precision.\n",
       "\n",
       "### **When It’s Optional or Not Used**\n",
       "1. **Journalism and Media**: Style guides like *The Associated Press (AP) Stylebook* generally omit the Oxford comma unless it’s necessary for clarity.\n",
       "\n",
       "2. **Informal Writing**: In casual writing, such as emails or social media, the Oxford comma is often omitted for brevity.\n",
       "\n",
       "3. **Regional Preferences**: In some regions or industries, the Oxford comma is less commonly used.\n",
       "\n",
       "### **Conclusion**\n",
       "The Oxford comma is not always mandatory, but it is often recommended for clarity and consistency, especially in formal writing. If you’re following a specific style guide, adhere to its rules. If not, consider using the Oxford comma when it helps avoid ambiguity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "md_display(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f031b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Recent advancements in NLP have shown that pre-training large language models on vast amounts of text and then fine-tuning them on specific tasks leads to significant improvements. However, this approach still requires large task-specific datasets for fine-tuning. In contrast, humans can learn new language tasks with just a few examples or simple instructions, a capability that current NLP systems lack. This research demonstrates that scaling up the size of language models enhances their ability to perform well on tasks with minimal examples (few-shot learning), sometimes even matching the performance of state-of-the-art fine-tuned models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\"\n",
    "prompt = f\"{text}\\n\\nTl;dr\"\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "md_display(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b99a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "自然语言处理（NLP）领域的突飞猛进主要归功于大型语言模型（LLMs）的发展，尤其是基于Transformer架构的预训练模型。这些模型通过在大规模语料库上进行训练，展现出了强大的语言理解和生成能力。随着模型参数规模的增加，LLMs不仅在许多NLP任务上取得了显著性能提升，还涌现出了一些小模型不具备的能力，如上下文学习。\n",
       "\n",
       "从2019年的谷歌T5到OpenAI的GPT系列，LLMs的参数量不断爆炸式增长，尤其是2022年底ChatGPT的发布，进一步引发了社会对LLMs的广泛关注。这些技术进步不仅推动了AI社区的发展，也改变了人们开发和使用AI算法的方式。\n",
       "\n",
       "未来，LLMs的发展可能会继续沿着以下几个方向进行：\n",
       "1. **模型规模的进一步扩大**：随着计算资源的增加，模型参数规模可能会继续增长，带来更强的性能。\n",
       "2. **自适应调优和微调**：通过更精细的调优方法，使模型在特定任务上表现更好。\n",
       "3. **多模态学习**：将语言模型与其他模态（如图像、音频）结合，实现更通用的智能。\n",
       "4. **可解释性和安全性**：提高模型的可解释性，确保其安全性和可靠性。\n",
       "\n",
       "总的来说，LLMs的快速发展为通用人工智能（AGI）的实现提供了新的可能性，但同时也带来了技术、伦理和社会等方面的挑战。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "为什么仿佛一夜之间，自然语言处理（NLP）领域就突然突飞猛进，摸到了通用人工智能的门槛？如今的大语言模型（LLM）发展到了什么程度？未来短时间内，AGI 的发展路线又将如何？\n",
    "\n",
    "自 20 世纪 50 年代图灵测试提出以来，人们始终在探索机器处理语言智能的能力。语言本质上是一个错综复杂的人类表达系统，受到语法规则的约束。因此，开发能够理解和精通语言的强大 AI 算法面临着巨大挑战。过去二十年，语言建模方法被广泛用于语言理解和生成，包括统计语言模型和神经语言模型。\n",
    "\n",
    "近些年，研究人员通过在大规模语料库上预训练 Transformer 模型产生了预训练语言模型（PLMs），并在解决各类 NLP 任务上展现出了强大的能力。并且研究人员发现模型缩放可以带来性能提升，因此他们通过将模型规模增大进一步研究缩放的效果。有趣的是，当参数规模超过一定水平时，这个更大的语言模型实现了显著的性能提升，并出现了小模型中不存在的能力，比如上下文学习。为了区别于 PLM，这类模型被称为大型语言模型（LLMs）。\n",
    "\n",
    "从 2019 年的谷歌 T5 到 OpenAI GPT 系列，参数量爆炸的大模型不断涌现。可以说，LLMs 的研究在学界和业界都得到了很大的推进，尤其去年 11 月底对话大模型 ChatGPT 的出现更是引起了社会各界的广泛关注。LLMs 的技术进展对整个 AI 社区产生了重要影响，并将彻底改变人们开发和使用 AI 算法的方式。\n",
    "\n",
    "考虑到 LLMs 的快速技术进步，中国人民大学的二十几位研究者通过背景知识、关键发现和主流技术等三方面回顾了 LLMs 的最新进展，尤其关注 LLMs 的预训练、自适应调优、使用和能力评估。此外他们还总结和开发 LLMs 的可用资源，讨论了未来发展方向等问题。对于领域内研究人员和工程师而言，这份综述是一份极其有用的学习资源。\n",
    "\"\"\"\n",
    "prompt = f\"{text}\\n\\nTl;dr\"\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "md_display(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202ff494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\n",
       "\n",
       "inquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\n",
       "\n",
       "Classified category:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The inquiry \"Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement\" would be classified under the category: **Hardware Support**. This is because it pertains to a physical component (the laptop keyboard) that requires repair or replacement."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "md_display(prompt)\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "md_display(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae33d7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Product description: A home milkshake maker\n",
       "Seed words: fast, healthy, compact.\n",
       "Product names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
       "\n",
       "Product description: A pair of shoes that can fit any foot size.\n",
       "Seed words: adaptable, fit, omni-fit."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Product names: AdaptSole, OmniFit, FlexFit, PerfectFit\n",
       "\n",
       "**Product Description for Home Milkshake Maker:**  \n",
       "\"Create delicious, **healthy** milkshakes in seconds with the **compact** and **fast** HomeShaker. Perfect for busy lifestyles, this milkshake maker blends your favorite ingredients into a creamy treat in no time. Whether you're craving a post-workout protein shake or a sweet dessert, the HomeShaker makes it easy and mess-free!\"\n",
       "\n",
       "**Product Description for Adaptable Shoes:**  \n",
       "\"Step into comfort with AdaptSole, the **adaptable** shoes designed to **fit** any foot size. Featuring innovative Omni-Fit technology, these shoes adjust to your unique shape, providing unmatched comfort and support. Perfect for travel, sports, or everyday wear, AdaptSole ensures a perfect fit every time!\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "md_display(prompt)\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "md_display(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai4beginners",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
